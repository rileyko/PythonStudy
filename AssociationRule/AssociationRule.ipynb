{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연관규칙 분석 (Association Rule Mining)\n",
    "## 1. 개요\n",
    "- 소비자 또는 일련의 사용자 그룹의 행동 간에 존재하는 동시 발생 관계를 분석하는 알고리즘\n",
    "- 대규모 DB에 존재하는 아이템 간의 관계를 규명하기 위해 사용하는 방법\n",
    "- 장바구니 분석(Market Basket Analysis) 또는 친밀도 분석(Affinity Analysis)라고도 불림\n",
    "- Ex) 월마트 사례\n",
    "    * 맥주와 기저귀를 비슷한 곳에 진열하니 매출이 향상됨 => 남편이 마트에 들러 물건을 살 때 부인의 부탁으로 아이 기저귀를 사면서 동시에 본인이 마실 맥주를 산다는 구매 패턴을 발견\n",
    "    * 즉, 데이터 분석을 통해 **전혀 관련성이 없는 맥주와 기저귀의 연결고리**를 알게되어 마케팅 전략에 반영한 사례\n",
    "\n",
    "## 2. 장점\n",
    "- 장바구니로 정의되는 하나의 Entity(장바구니)와 그 장바구니에 기록된 품목 이름(맥주, 기저귀)만 있다면 바로 분석이 가능함 -> 많은 조건을 고려하느라 소요되는 시간을 벌 수 있음\n",
    "- 특별한 domain knowledge가 없어도, 유의미한 여러 패턴을 식별 할 수 있음\n",
    "- 반드시 추천 시스템이 아니더라도, 다양한 목적에 맞게 분석을 응용하여 쓸 수 있음\n",
    "\n",
    "## 3. 단점\n",
    "- 상품(item) 간의 인과관계는 알 수 없음, 즉 선행여부는 반영될 수 없음\n",
    "    * 인과관계 : 기저귀를 사면, 맥주도 삼(p→q) \n",
    "    * 상관관계 :\n",
    "        * 기저귀랑 맥주 둘다 삼\n",
    "        * 기저귀를 담은 고객(p)은 맥주도 담을(q) 확률(=P(q∣p))이 높다고는 할 수 있으나, 그렇다고 기저귀를 담지 않으면(!p) 맥주도 담지 않을(!q) 확률이 높다'가 성립할 수 없음\n",
    "- 상품 별 수량은 고려되지 않음\n",
    "- 상품명 외에는 어떤 변수도 고려되지 않음\n",
    "\n",
    "예시 이미지  \n",
    "![img](imgs/AssociationBurger.png) \n",
    "\n",
    "## 4. 알고리즘\n",
    "1. 규칙 발견\n",
    "    1. 특정 제품을 함께 구매할 가능성 : 햄버거 패티를 사는 사람은 햄버거 롤, 케펍, 머스타드, 토마토 등을 함께 사는 경향이 있음\n",
    "    2. 상품 친밀도가 모호한 경우 :\n",
    "        * 치약 & 참치캔 : 일부 지역에서는 참치 요리를 한 후 즉각적으로 칫솔질하는 지역이 있을 수도 있지만 일반적으로 친밀도가 약함\n",
    "    3. 영수증 한 장을 하나의 거래로 보고 한 줄에 기록\n",
    "    4. 지지도(Support)\n",
    "        - 해당 아이템이 포함된 거래의 비율\n",
    "        - 품목A & 품목B 포함 거래수 / 전체 거래수\n",
    "        - Num of {감자, 햄버거} / Total\n",
    "    5. 신뢰도(Cofidence)\n",
    "        - 예측의 정확성\n",
    "        - 항목A의 거래 중에서 항목 B가 포함된 거래의 비율\n",
    "        - {양파, 햄버거} -> {맥주} : 100% 신뢰도\n",
    "    6. 향상도(Lift)\n",
    "        - A->B의 연관규칙에서 임의로 B가 구매되는 경우에 비해 A와의 관계가 고려되어 구매되는 경우의 비율\n",
    "        - Lift = 1 => 독립적 관계\n",
    "        - Lift > 1 => 양의 상관관계 (맥주 & 안주)\n",
    "        - Lift < 1 => 음의 상관관계 (설사약 & 변비약)\n",
    "        \n",
    "## 5. 관련 통계\n",
    "- 개별 확률\n",
    "    * P(A) : 상품 A를 구매할 확률\n",
    "    * P(B) : 상품 B를 구매할 확률\n",
    "- 지지도\n",
    "    * A와 B를 동시에 구매할 확률\n",
    "    * 동시거래 건수 / 전체거래 건수\n",
    "- 신뢰도\n",
    "    * A를 구매한 거래 중에서 B를 구매한 확률\n",
    "    * 지지도 / P(A) \n",
    "- 향상도\n",
    "    * A -> B 의 연관규칙에서 임의로 B가 구매되는 경우에 비해서 A와의 관계가 고려되어 구매되는 경우의 비율\n",
    "    * 신뢰도 / P(B)\n",
    "    * 향상도 > 1 => 양의관계이므로 동시 구매 가능성 ⬆️\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 알고리즘 종류\n",
    "\n",
    "### 선험적 알고리즘(Apriori 알고리즘)\n",
    "- 개념\n",
    "    - 거리 관련 빈도 패턴 마이닝으로 연관 규칙 학습에 사용되는 알고리즘\n",
    "    - 모든 아이템셋을 찾기보다는 아주 빈번한 아이템셋의 특성만을 찾음\n",
    "    - 드물게 나타나는 조합을 무시하여 아이템셋의 크기를 줄여줌\n",
    "\n",
    "- 장점\n",
    "    - 원리가 간단해서 쉽게 이해할 수 있고 이 의미를 쉽게 파악할 수 있음\n",
    "    - 유의한 연관성을 갖는 구매패턴을 다양하게 찾아줌\n",
    "\n",
    "- 단점\n",
    "    - 데이터가 크다면 속도가 느리고 연산량이 많아짐\n",
    "    - 실제 알고리즘을 사용하게 되면 너무 많은 연관상품들이 나타나는 문제 발생\n",
    "    - 연관 상품들이 상관관계는 의미하지만 그것이 인과를 의미하지 않기 때문에, 결과만을 본다면 어떤 것이 원인인지 파악하기 힘듬\n",
    "\n",
    "- 알고리즘 원리\n",
    "    1. k개의 아이템을 가지고 단일항목집단 생성\n",
    "    2. 단일항목집단에서 지지도 계산 후 최소 지지도 이상의 항목만 선택\n",
    "    3. 2에서 선택된 항목 만을 대상으로 2개항목집단 생성\n",
    "    4. 2개항목집단에서 최소 지지도 혹은 신뢰도 이상의 항목만 선택\n",
    "    5. 위의 과정을 k개의 k-item frequent set을 생성할 때까지 반복\n",
    "\n",
    "- 연관도 추출 방법\n",
    "    * Association Rule을 적용하여 지지도(Support), 신뢰도(Confidence) 그리고 향상도(Lift)\n",
    "\n",
    "\n",
    "### 반발 패턴 성장 알고리즘(FP Growth 알고리즘, Frequent Pattern)\n",
    "- 개념\n",
    "    - **Tree** 구조를 통해 **Apriori 알고리즘을 개선**한 알고리즘\n",
    "    - 데이터셋에서 해당 아이템의 발생 횟수를 측정한 후 문자열을 저장할 수 있는 순차적인 데이터 구조를 지닌 트리를 생성함\n",
    "    - 다수 거래에서 가장 빈번히 등장하는 아이템을 트리 뿌리와 가장 가까운 요소로서 나타냄\n",
    "\n",
    "- 장점\n",
    "    - Tree구조이기 때문에 Apriori보다 훨씬 빠름, DB에서 스캔하는 횟수도 줄어듬. \n",
    "        - Apriori : 최소 한 번의 DB스캔에서부터 가장 긴 트랜잭션의 아이템 셋을 뒤져야 할 가능성 존재\n",
    "        - FP-Growth : 첫번째 스캔으로 단일 항목집단을 만들고, 두 번째 스캔으로 Tree구조를 - 완성합니다. 완성한 FP-Tree를 이용해서 분석하면 되니까, 딱 2번만 스캔하면 됨\n",
    "            - 후보 Itemset을 생성할 필요없이, Tree만 구성하면 끝임\n",
    "\n",
    "- 단점\n",
    "    - 대용량 데이터 셋에서 메모리를 효율적으로 사용하지 않음\n",
    "    - Apriori에 비해 설계하기 어렵고, 서포트의 계산은 무조건 FP-Tree가 만들어져야 가능함\n",
    "\n",
    "- 알고리즘 원리\n",
    "    1. 모든 거래를 확인해 각 아이템마다의 서포트를 계산하고 최소 지지도 이상의 아이템만 선택\n",
    "    2. 모든 거래에서 빈도가 높은 아이템 순서대로 순서를 정렬(여기서 부터 달라짐)\n",
    "    3. 부모 노드를 중심으로 거래를 자식노드로 추가해주면서 tree를 생성\n",
    "    4. 새로운 아이템이 나올 경우에는 부모노드부터 시작하고, 그렇지 않으면 기존의 노드에서 확장\n",
    "    5. 위의 과정을 모든 거래에 대해 반복하여 FP Tree를 만들고 최소 지지도 이상의 패턴만을 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.google.com/presentation/d/1Yxlo3HuWl9VUVx7-0FYdakxXFSS2Ub8S6tAFkeb8BG0/edit#slide=id.g122b624f265_3_1627\n",
    "\n",
    "https://www.youtube.com/watch?v=CLpJ6cWiJPY\n",
    "(37분)\n",
    "\n",
    "https://gbi2max.quip.com/3OCsAjJ93jf7/Data-Platform-for-Salesforce-Enterprise-Customers\n",
    "\n",
    "https://lucid.app/lucidchart/a9d2e97b-4886-4791-a01a-fd9dbb2cb794/edit?beaconFlowId=87A83C9B05F3AB11&invitationId=inv_5c942edd-7d63-49d3-a796-a22dbd1fcbc0&page=0_0#\n",
    "\n",
    "https://www.notion.so/335e379cca8148b8b11d2a130d219bba?v=f1f8e28d224a4f72986ae5c86c3f4295&p=c2af1de040ba4629bf13902d81a19deb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f4446411cb4823f72a41c2d680bb6d6d7a87f456e42fc689e4e496b6ebd49bb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('woodeem2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

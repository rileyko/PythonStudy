{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 명함인식 OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.13 (default, Mar 28 2022, 07:24:34) \n",
      "[Clang 12.0.0 ]\n",
      "4.5.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'미0\\n\\nae\\n공인중개사\\n\\n공인중개사 깁 a =\\n\\nTEL —010.2235.6675\\n\\nFAX = 051.524.6675\\n\\nE-MAIL junghun12@naver.com\\n\\nADD _ 부산 해운대구 재송로 32번길 17\\n\\n \\n\\x0c'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모듈 있는지 확인\n",
    "import sys\n",
    "import cv2\n",
    "import pytesseract \n",
    "from PIL import Image\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd= r'/Users/woodeem/opt/anaconda3/envs/rnd/bin/tesseract'\n",
    "\n",
    "print(sys.version)\n",
    "print(cv2.__version__)\n",
    "pytesseract.image_to_string(Image.open('bizcardsample/SampleImg.jpeg'), lang='kor+eng', config='--psm 1 -c preserve_interword_spaces=1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biz Logic\n",
    "1. 이미지 읽기\n",
    "2. 이미지로부터 명함 엣지 추출\n",
    "3. 이미지 평면화\n",
    "4. 스캔한 효과를 줘서 조명 영향 제거\n",
    "5. OCR 엔진을 이용해 글자 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV - 이미지 읽기, 쓰기 및 표시하기\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def handle_image():\n",
    "    imgfile = 'bizcardsample/HairSample.png'\n",
    "    img = cv2.imread(imgfile, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    cv2.imshow('image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    handle_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV - 이미지 읽기, 쓰기 및 표시하기\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def handle_image():\n",
    "    imgfile = 'bizcardsample/HairSample.png'\n",
    "    img = cv2.imread(imgfile, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('image', img)\n",
    "    k = cv2.waitKey(0)\n",
    "    \n",
    "    # wait for ESC key to exit\n",
    "    if k == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "    # wait for 's' key to save and exit\n",
    "    elif k == ord('s'):\n",
    "        cv2.imwrite('bizcardsample/grayImage.png', img)\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    handle_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 명함 외곽 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV 도형 외곽 추출하기\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "def contour():\n",
    "    imgfile = 'bizcardsample/HairSample.png'\n",
    "    img = cv2.imread(imgfile)\n",
    "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    edge = cv2.Canny(imgray, 100, 200)\n",
    "    contours, hierarchy = cv2.findContours(edge, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    cv2.imshow('edge', edge)\n",
    "    cv2.drawContours(img, contours, -1, (0, 255, 0), 1)\n",
    "    cv2.imshow('Contour', img)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    contour()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 명함이 구겨져 있거나 정확한 직사각형이 아니면, 도형을 근사해서 계산함으로써 과적합(Overfitting) 방지함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n",
      "(25, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "# OpenCV - 도형 외곽 추출하기\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "def contour_approx():\n",
    "    imgfile = 'bizcardsample/HairSample.png'\n",
    "    img = cv2.imread(imgfile)\n",
    "    img2 = img.copy()\n",
    "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    edge = cv2.Canny(imgray, 100, 200)\n",
    "    contours, hierarchy = cv2.findContours(edge, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print(len(contours))\n",
    "    print(contours[0].shape)\n",
    "    \n",
    "    cnt = contours[0]\n",
    "    cv2.drawContours(img, [cnt], 0, (0, 255, 0), 3)\n",
    "    \n",
    "    epsilon = 0.1 * cv2.arcLength(cnt, True)\n",
    "    \n",
    "    approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "    \n",
    "    cv2.drawContours(img2, [approx], 0, (0, 255, 0), 3)\n",
    "    \n",
    "    cv2.imshow('Contour', img)\n",
    "    cv2.imshow('Approx', img2)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    contour_approx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 투영변환 : 외곽으로 그려진 영역을 반듯하게 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV - 투영변환 구현하기\n",
    "import numpy as np \n",
    "import cv2\n",
    "\n",
    "def warpAffine():\n",
    "    img = cv2.imread('bizcardsample/HairSample.png')\n",
    "    \n",
    "    pts1 = np.float32([[50,50], [200,50], [20, 200]])\n",
    "    pts2 = np.float32([[70,100], [220,50], [150, 250]])\n",
    "    \n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "    \n",
    "    result = cv2.warpAffine(img, M, (500, 300))\n",
    "    \n",
    "    cv2.imshow('original', img)\n",
    "    cv2.imshow('Affine Transform', result)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warpAffine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def warpPerspective():\n",
    "    img = cv2.imread('bizcardsample/ObidjonNameCard.jpeg')\n",
    "    \n",
    "    topLeft = [127, 157]\n",
    "    topRight = [448, 152]\n",
    "    bottomRight = [579, 526]\n",
    "    bottomLeft = [54, 549]\n",
    "    \n",
    "    pts1 = np.float32([topLeft, topRight, bottomRight, bottomLeft])\n",
    "    \n",
    "    w1 = abs(bottomRight[0] - bottomLeft[0])\n",
    "    w2 = abs(topRight[0] - topLeft[0])\n",
    "    h1 = abs(topRight[1] - bottomRight[1])\n",
    "    h2 = abs(topLeft[1] - bottomLeft[1])\n",
    "    \n",
    "    minWidth = min([w1, w2])\n",
    "    minHeight = min([h1, h2])\n",
    "    \n",
    "    pts2 = np.float32([[0,0], [minWidth-1,0], [minWidth-1, minHeight-1], [0,minHeight-1]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    \n",
    "    result = cv2.warpPerspective(img, M, (int(minWidth), int(minHeight)))\n",
    "    \n",
    "    cv2.imshow('original', img)\n",
    "    cv2.imshow('Warp Transform', result)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warpPerspective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스캔한 효과를 줘서 조명의 영향 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV - 스캔 효과 주기\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Callback Function for Trackbar (but do not any work)\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "def global_threshold():\n",
    "    imgfile = 'bizcardsample/HairSample.png'\n",
    "    img = cv2.imread(imgfile, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    r = 600.0 / img.shape[0]\n",
    "    dim = (int(img.shape[1] * r), 600)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    WindowName = \"Window\"\n",
    "    TrackbarName = \"Threshold\"\n",
    "    \n",
    "    cv2.namedWindow(WindowName)\n",
    "    cv2.createTrackbar(TrackbarName, WindowName, 50, 255, nothing)\n",
    "    Threshold = np.zeros(img.shape, np.uint8)\n",
    "    \n",
    "    while True:\n",
    "        TrackbarPos = cv2.getTrackbarPos(TrackbarName, WindowName)\n",
    "        cv2.threshold(img, TrackbarPos, 255, cv2.THRESH_BINARY, Threshold)\n",
    "        cv2.imshow(WindowName, Threshold)\n",
    "        \n",
    "        k = cv2.waitKey(0)\n",
    "        if k == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            cv2.waitKey(1)\n",
    "            break\n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    global_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold 자동으로 구하기 & 조명 영향 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV - 스캔 효과 주기 (2)\n",
    "import cv2\n",
    "def adaptive_threshold():\n",
    "    imgfile = 'bizcardsample/HairSample.png'\n",
    "    img = cv2.imread(imgfile, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    r = 600.0 / img.shape[0]\n",
    "    dim = (int(img.shape[1] * r), 600)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    result_without_blur = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "    result_with_blur = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "    cv2.imshow('Without Blur', result_without_blur)\n",
    "    cv2.imshow('With Blur', result_with_blur)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    adaptive_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🦾 명함인식 구현 🦾 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP1 : Edge Detection\n",
      "STEP2 : Find Contours of Paper\n",
      "Step3 : Apply Perspective transform\n",
      "Step4 : Apply Adaptive Threshold\n",
      "때에 |.\n",
      "consulting partner\n",
      "\n",
      "사이드카몰로브 아크롬\n",
      "\n",
      "연구원\n",
      "기엽부설연구소\n",
      "\n",
      "0312100\n",
      "\n",
      "아이트멕스\n",
      "\n",
      "rT\n",
      "\n",
      "Mobile 010 5900 5434\n",
      "Tel       02 365 2187\n",
      "Fax       02 365 2093\n",
      "akrom@i2max.co.kr\n",
      "\n",
      "(주)아이투맥스\n",
      "서울시 마포구 마포대로 137,\n",
      "KPX' &} 7증 (04143)\n",
      "\n",
      "{\n",
      "\n",
      "i\n",
      "3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step1. Edge Detection\n",
    "# 라이브러리 로드\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# 이미지 로드 후 높이 비율 맞추기\n",
    "image = cv2.imread('bizcardsample/Akrom_Kor.jpeg')\n",
    "orig = image.copy()\n",
    "r = 800.0 / image.shape[0]\n",
    "dim = (int(image.shape[1] * r), 800)\n",
    "image = cv2.resize(image, dim, interpolation= cv2.INTER_AREA)\n",
    "\n",
    "# Gray Scale 로 변환후 엣지 찾기\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "edged = cv2.Canny(gray, 20, 75)\n",
    "\n",
    "# 원본 이미지를 보여주고, Edge 디텍션\n",
    "print (\"STEP1 : Edge Detection\")\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "# ---------------------------------\n",
    "# Step2. Find Contours of Paper\n",
    "# Edge 윤곽 찾기\n",
    "\n",
    "(cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE) # findContours를 통해 contours들을 반환받음\n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse=True)\n",
    "\n",
    "# contour 찾기 반복(4개의 포인트)\n",
    "for c in cnts:\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "    \n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break\n",
    "\n",
    "# outlne 프린팅\n",
    "print(\"STEP2 : Find Contours of Paper\")\n",
    "cv2.drawContours(image, cnts,  -1, (0, 255, 0), 1)\n",
    "cv2.imshow(\"Outline\", image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "# ---------------------------------\n",
    "# Step3. Apply Perspective Transform\n",
    "# 이미지 똑바로 세우기\n",
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\") # 4개 꼭지점 좌표 입력할 4x2 행렬 생성\n",
    "\n",
    "    s = pts.sum(axis = 1)       # (x, y) 좌표에서 x+y 계산 (axis 0=열, 1=행)\n",
    "    rect[0] = pts[np.argmin(s)] # x+y의 최대값 (topLeft)\n",
    "    rect[2] = pts[np.argmax(s)] # x+y의 최소값 (bottomRight)\n",
    "\n",
    "    diff = np.diff(pts, axis = 1)  # (x, y) 좌표에서 y-x 계산 (axis 0=열, 1=행)\n",
    "    rect[1] = pts[np.argmin(diff)] # y-x의 최소값 (topRight)\n",
    "    rect[3] = pts[np.argmax(diff)] # y-x의 최대값 (bottomLeft)\n",
    "    return rect\n",
    "\n",
    "rect = order_points(screenCnt.reshape(4, 2) / r)\n",
    "(topLeft, topRight, bottomRight, bottomLeft) = rect\n",
    "\n",
    "w1 = abs(bottomRight[0] - bottomLeft[0])    # 하단 폭\n",
    "w2 = abs(topRight[0] - topLeft[0])          # 상단 폭\n",
    "h1 = abs(topRight[1] - bottomRight[1])      # 우측 높이\n",
    "h2 = abs(topLeft[1] - bottomLeft[1])        # 좌측 높이\n",
    "\n",
    "maxWidth = int(max([w1, w2]))\n",
    "maxHeight = int(max([h1, h2]))\n",
    "\n",
    "dst = np.float32([[0, 0], [maxWidth, 0], [maxWidth, maxHeight], [0, maxHeight]]) # 변환될 크기만큼 행렬 생성\n",
    "M = cv2.getPerspectiveTransform(rect, dst) # getPerspectiveTransform()함수를 통해서 나머지 픽셀을 옮기는 매트릭스 M에 반환\n",
    "warped = cv2.warpPerspective(orig, M, (maxWidth, maxHeight)) # M을 warpPerspective()에 넣음으로써 최종적으로 반듯한 사각형으로 변환된 이미지를 받음\n",
    "\n",
    "\n",
    "#원본과 스캔이미지 보기\n",
    "print(\"Step3 : Apply Perspective transform\")\n",
    "cv2.imshow(\"Warped\", warped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# Step3. Apply Adaptive Threshold\n",
    "# 이미지 스캔효과주기\n",
    "warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "warped = cv2.adaptiveThreshold(warped, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "\n",
    "print(\"Step4 : Apply Adaptive Threshold\")\n",
    "cv2.imshow(\"Original\", orig)\n",
    "cv2.imshow(\"Scanned\", warped)\n",
    "img2 = cv2.imwrite('samples/scannedImage.png', warped)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "\n",
    "def ocr_tesseract(img):\n",
    "    im = Image.open(img)\n",
    "    text = pytesseract.image_to_string(im, lang='kor+eng')\n",
    "    im.show()\n",
    "    print(text)\n",
    "    \n",
    "ocr_tesseract('samples/scannedImage.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.5\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ocr_tesseract() missing 1 required positional argument: 'img'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2p/mfwxnc5s0x1dkdkjmn_yt5880000gn/T/ipykernel_20628/1972297575.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mocr_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: ocr_tesseract() missing 1 required positional argument: 'img'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "def ocr_tesseract(img):\n",
    "    im = Image.open(img)\n",
    "    text = pytesseract.image_to_string(im, lang='kor+eng')\n",
    "    im.show()\n",
    "    print(text)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ocr_tesseract()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc836340034460e9c5583b996b053fe1fe7ffeb52054821d3ff9d502e04de020"
  },
  "kernelspec": {
   "display_name": "woodeemkn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

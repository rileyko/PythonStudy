{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ëª…í•¨ì¸ì‹ OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.13 (default, Mar 28 2022, 07:24:34) \n",
      "[Clang 12.0.0 ]\n",
      "4.5.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ë¯¸0\\n\\nae\\nê³µì¸ì¤‘ê°œì‚¬\\n\\nê³µì¸ì¤‘ê°œì‚¬ ê¹ a =\\n\\nTEL â€”010.2235.6675\\n\\nFAX = 051.524.6675\\n\\nE-MAIL junghun12@naver.com\\n\\nADD _ ë¶€ì‚° í•´ìš´ëŒ€êµ¬ ìž¬ì†¡ë¡œ 32ë²ˆê¸¸ 17\\n\\n \\n\\x0c'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë“ˆ ìžˆëŠ”ì§€ í™•ì¸\n",
    "import sys\n",
    "import cv2\n",
    "import pytesseract \n",
    "from PIL import Image\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd= r'/Users/woodeem/opt/anaconda3/envs/rnd/bin/tesseract'\n",
    "\n",
    "print(sys.version)\n",
    "print(cv2.__version__)\n",
    "pytesseract.image_to_string(Image.open('bizcardsample/SampleImg.jpeg'), lang='kor+eng', config='--psm 1 -c preserve_interword_spaces=1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biz Logic\n",
    "1. ì´ë¯¸ì§€ ì½ê¸°\n",
    "2. ì´ë¯¸ì§€ë¡œë¶€í„° ëª…í•¨ ì—£ì§€ ì¶”ì¶œ\n",
    "3. ì´ë¯¸ì§€ í‰ë©´í™”\n",
    "4. ìŠ¤ìº”í•œ íš¨ê³¼ë¥¼ ì¤˜ì„œ ì¡°ëª… ì˜í–¥ ì œê±°\n",
    "5. OCR ì—”ì§„ì„ ì´ìš©í•´ ê¸€ìž ì¸ì‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV - ì´ë¯¸ì§€ ì½ê¸°, ì“°ê¸° ë° í‘œì‹œí•˜ê¸°\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def handle_image():\n",
    "    imgfile = 'bizcardsample/HairSample.png'\n",
    "    img = cv2.imread(imgfile, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    cv2.imshow('image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    handle_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV - ì´ë¯¸ì§€ ì½ê¸°, ì“°ê¸° ë° í‘œì‹œí•˜ê¸°\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def handle_image():\n",
    "    imgfile = 'bizcardsample/HairSample.png'\n",
    "    img = cv2.imread(imgfile, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('image', img)\n",
    "    k = cv2.waitKey(0)\n",
    "    \n",
    "    # wait for ESC key to exit\n",
    "    if k == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "    # wait for 's' key to save and exit\n",
    "    elif k == ord('s'):\n",
    "        cv2.imwrite('bizcardsample/grayImage.png', img)\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    handle_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª…í•¨ ì™¸ê³½ ì¶”ì¶œí•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV ë„í˜• ì™¸ê³½ ì¶”ì¶œí•˜ê¸°\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "def contour():\n",
    "    imgfile = 'bizcardsample/HairSample.png'\n",
    "    img = cv2.imread(imgfile)\n",
    "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    edge = cv2.Canny(imgray, 100, 200)\n",
    "    contours, hierarchy = cv2.findContours(edge, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    cv2.imshow('edge', edge)\n",
    "    cv2.drawContours(img, contours, -1, (0, 255, 0), 1)\n",
    "    cv2.imshow('Contour', img)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    contour()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª…í•¨ì´ êµ¬ê²¨ì ¸ ìžˆê±°ë‚˜ ì •í™•í•œ ì§ì‚¬ê°í˜•ì´ ì•„ë‹ˆë©´, ë„í˜•ì„ ê·¼ì‚¬í•´ì„œ ê³„ì‚°í•¨ìœ¼ë¡œì¨ ê³¼ì í•©(Overfitting) ë°©ì§€í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247\n",
      "(25, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "# OpenCV - ë„í˜• ì™¸ê³½ ì¶”ì¶œí•˜ê¸°\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "def contour_approx():\n",
    "    imgfile = 'bizcardsample/HairSample.png'\n",
    "    img = cv2.imread(imgfile)\n",
    "    img2 = img.copy()\n",
    "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    edge = cv2.Canny(imgray, 100, 200)\n",
    "    contours, hierarchy = cv2.findContours(edge, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print(len(contours))\n",
    "    print(contours[0].shape)\n",
    "    \n",
    "    cnt = contours[0]\n",
    "    cv2.drawContours(img, [cnt], 0, (0, 255, 0), 3)\n",
    "    \n",
    "    epsilon = 0.1 * cv2.arcLength(cnt, True)\n",
    "    \n",
    "    approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "    \n",
    "    cv2.drawContours(img2, [approx], 0, (0, 255, 0), 3)\n",
    "    \n",
    "    cv2.imshow('Contour', img)\n",
    "    cv2.imshow('Approx', img2)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    contour_approx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### íˆ¬ì˜ë³€í™˜ : ì™¸ê³½ìœ¼ë¡œ ê·¸ë ¤ì§„ ì˜ì—­ì„ ë°˜ë“¯í•˜ê²Œ ë³€í™˜í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV - íˆ¬ì˜ë³€í™˜ êµ¬í˜„í•˜ê¸°\n",
    "import numpy as np \n",
    "import cv2\n",
    "\n",
    "def warpAffine():\n",
    "    img = cv2.imread('bizcardsample/HairSample.png')\n",
    "    \n",
    "    pts1 = np.float32([[50,50], [200,50], [20, 200]])\n",
    "    pts2 = np.float32([[70,100], [220,50], [150, 250]])\n",
    "    \n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "    \n",
    "    result = cv2.warpAffine(img, M, (500, 300))\n",
    "    \n",
    "    cv2.imshow('original', img)\n",
    "    cv2.imshow('Affine Transform', result)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warpAffine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def warpPerspective():\n",
    "    img = cv2.imread('bizcardsample/ObidjonNameCard.jpeg')\n",
    "    \n",
    "    topLeft = [127, 157]\n",
    "    topRight = [448, 152]\n",
    "    bottomRight = [579, 526]\n",
    "    bottomLeft = [54, 549]\n",
    "    \n",
    "    pts1 = np.float32([topLeft, topRight, bottomRight, bottomLeft])\n",
    "    \n",
    "    w1 = abs(bottomRight[0] - bottomLeft[0])\n",
    "    w2 = abs(topRight[0] - topLeft[0])\n",
    "    h1 = abs(topRight[1] - bottomRight[1])\n",
    "    h2 = abs(topLeft[1] - bottomLeft[1])\n",
    "    \n",
    "    minWidth = min([w1, w2])\n",
    "    minHeight = min([h1, h2])\n",
    "    \n",
    "    pts2 = np.float32([[0,0], [minWidth-1,0], [minWidth-1, minHeight-1], [0,minHeight-1]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    \n",
    "    result = cv2.warpPerspective(img, M, (int(minWidth), int(minHeight)))\n",
    "    \n",
    "    cv2.imshow('original', img)\n",
    "    cv2.imshow('Warp Transform', result)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warpPerspective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìŠ¤ìº”í•œ íš¨ê³¼ë¥¼ ì¤˜ì„œ ì¡°ëª…ì˜ ì˜í–¥ ì œê±°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV - ìŠ¤ìº” íš¨ê³¼ ì£¼ê¸°\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Callback Function for Trackbar (but do not any work)\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "def global_threshold():\n",
    "    imgfile = 'bizcardsample/HairSample.png'\n",
    "    img = cv2.imread(imgfile, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    r = 600.0 / img.shape[0]\n",
    "    dim = (int(img.shape[1] * r), 600)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    WindowName = \"Window\"\n",
    "    TrackbarName = \"Threshold\"\n",
    "    \n",
    "    cv2.namedWindow(WindowName)\n",
    "    cv2.createTrackbar(TrackbarName, WindowName, 50, 255, nothing)\n",
    "    Threshold = np.zeros(img.shape, np.uint8)\n",
    "    \n",
    "    while True:\n",
    "        TrackbarPos = cv2.getTrackbarPos(TrackbarName, WindowName)\n",
    "        cv2.threshold(img, TrackbarPos, 255, cv2.THRESH_BINARY, Threshold)\n",
    "        cv2.imshow(WindowName, Threshold)\n",
    "        \n",
    "        k = cv2.waitKey(0)\n",
    "        if k == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            cv2.waitKey(1)\n",
    "            break\n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    global_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold ìžë™ìœ¼ë¡œ êµ¬í•˜ê¸° & ì¡°ëª… ì˜í–¥ ì¤„ì´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV - ìŠ¤ìº” íš¨ê³¼ ì£¼ê¸° (2)\n",
    "import cv2\n",
    "def adaptive_threshold():\n",
    "    imgfile = 'bizcardsample/HairSample.png'\n",
    "    img = cv2.imread(imgfile, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    r = 600.0 / img.shape[0]\n",
    "    dim = (int(img.shape[1] * r), 600)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    result_without_blur = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "    result_with_blur = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "    cv2.imshow('Without Blur', result_without_blur)\n",
    "    cv2.imshow('With Blur', result_with_blur)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    adaptive_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¦¾ ëª…í•¨ì¸ì‹ êµ¬í˜„ ðŸ¦¾ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP1 : Edge Detection\n",
      "STEP2 : Find Contours of Paper\n",
      "Step3 : Apply Perspective transform\n",
      "Step4 : Apply Adaptive Threshold\n",
      "ë•Œì— |.\n",
      "consulting partner\n",
      "\n",
      "ì‚¬ì´ë“œì¹´ëª°ë¡œë¸Œ ì•„í¬ë¡¬\n",
      "\n",
      "ì—°êµ¬ì›\n",
      "ê¸°ì—½ë¶€ì„¤ì—°êµ¬ì†Œ\n",
      "\n",
      "0312100\n",
      "\n",
      "ì•„ì´íŠ¸ë©•ìŠ¤\n",
      "\n",
      "rT\n",
      "\n",
      "Mobile 010 5900 5434\n",
      "Tel       02 365 2187\n",
      "Fax       02 365 2093\n",
      "akrom@i2max.co.kr\n",
      "\n",
      "(ì£¼)ì•„ì´íˆ¬ë§¥ìŠ¤\n",
      "ì„œìš¸ì‹œ ë§ˆí¬êµ¬ ë§ˆí¬ëŒ€ë¡œ 137,\n",
      "KPX' &} 7ì¦ (04143)\n",
      "\n",
      "{\n",
      "\n",
      "i\n",
      "3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step1. Edge Detection\n",
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# ì´ë¯¸ì§€ ë¡œë“œ í›„ ë†’ì´ ë¹„ìœ¨ ë§žì¶”ê¸°\n",
    "image = cv2.imread('bizcardsample/Akrom_Kor.jpeg')\n",
    "orig = image.copy()\n",
    "r = 800.0 / image.shape[0]\n",
    "dim = (int(image.shape[1] * r), 800)\n",
    "image = cv2.resize(image, dim, interpolation= cv2.INTER_AREA)\n",
    "\n",
    "# Gray Scale ë¡œ ë³€í™˜í›„ ì—£ì§€ ì°¾ê¸°\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "edged = cv2.Canny(gray, 20, 75)\n",
    "\n",
    "# ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë³´ì—¬ì£¼ê³ , Edge ë””í…ì…˜\n",
    "print (\"STEP1 : Edge Detection\")\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "# ---------------------------------\n",
    "# Step2. Find Contours of Paper\n",
    "# Edge ìœ¤ê³½ ì°¾ê¸°\n",
    "\n",
    "(cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE) # findContoursë¥¼ í†µí•´ contoursë“¤ì„ ë°˜í™˜ë°›ìŒ\n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse=True)\n",
    "\n",
    "# contour ì°¾ê¸° ë°˜ë³µ(4ê°œì˜ í¬ì¸íŠ¸)\n",
    "for c in cnts:\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "    \n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break\n",
    "\n",
    "# outlne í”„ë¦°íŒ…\n",
    "print(\"STEP2 : Find Contours of Paper\")\n",
    "cv2.drawContours(image, cnts,  -1, (0, 255, 0), 1)\n",
    "cv2.imshow(\"Outline\", image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "# ---------------------------------\n",
    "# Step3. Apply Perspective Transform\n",
    "# ì´ë¯¸ì§€ ë˜‘ë°”ë¡œ ì„¸ìš°ê¸°\n",
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\") # 4ê°œ ê¼­ì§€ì  ì¢Œí‘œ ìž…ë ¥í•  4x2 í–‰ë ¬ ìƒì„±\n",
    "\n",
    "    s = pts.sum(axis = 1)       # (x, y) ì¢Œí‘œì—ì„œ x+y ê³„ì‚° (axis 0=ì—´, 1=í–‰)\n",
    "    rect[0] = pts[np.argmin(s)] # x+yì˜ ìµœëŒ€ê°’ (topLeft)\n",
    "    rect[2] = pts[np.argmax(s)] # x+yì˜ ìµœì†Œê°’ (bottomRight)\n",
    "\n",
    "    diff = np.diff(pts, axis = 1)  # (x, y) ì¢Œí‘œì—ì„œ y-x ê³„ì‚° (axis 0=ì—´, 1=í–‰)\n",
    "    rect[1] = pts[np.argmin(diff)] # y-xì˜ ìµœì†Œê°’ (topRight)\n",
    "    rect[3] = pts[np.argmax(diff)] # y-xì˜ ìµœëŒ€ê°’ (bottomLeft)\n",
    "    return rect\n",
    "\n",
    "rect = order_points(screenCnt.reshape(4, 2) / r)\n",
    "(topLeft, topRight, bottomRight, bottomLeft) = rect\n",
    "\n",
    "w1 = abs(bottomRight[0] - bottomLeft[0])    # í•˜ë‹¨ í­\n",
    "w2 = abs(topRight[0] - topLeft[0])          # ìƒë‹¨ í­\n",
    "h1 = abs(topRight[1] - bottomRight[1])      # ìš°ì¸¡ ë†’ì´\n",
    "h2 = abs(topLeft[1] - bottomLeft[1])        # ì¢Œì¸¡ ë†’ì´\n",
    "\n",
    "maxWidth = int(max([w1, w2]))\n",
    "maxHeight = int(max([h1, h2]))\n",
    "\n",
    "dst = np.float32([[0, 0], [maxWidth, 0], [maxWidth, maxHeight], [0, maxHeight]]) # ë³€í™˜ë  í¬ê¸°ë§Œí¼ í–‰ë ¬ ìƒì„±\n",
    "M = cv2.getPerspectiveTransform(rect, dst) # getPerspectiveTransform()í•¨ìˆ˜ë¥¼ í†µí•´ì„œ ë‚˜ë¨¸ì§€ í”½ì…€ì„ ì˜®ê¸°ëŠ” ë§¤íŠ¸ë¦­ìŠ¤ Mì— ë°˜í™˜\n",
    "warped = cv2.warpPerspective(orig, M, (maxWidth, maxHeight)) # Mì„ warpPerspective()ì— ë„£ìŒìœ¼ë¡œì¨ ìµœì¢…ì ìœ¼ë¡œ ë°˜ë“¯í•œ ì‚¬ê°í˜•ìœ¼ë¡œ ë³€í™˜ëœ ì´ë¯¸ì§€ë¥¼ ë°›ìŒ\n",
    "\n",
    "\n",
    "#ì›ë³¸ê³¼ ìŠ¤ìº”ì´ë¯¸ì§€ ë³´ê¸°\n",
    "print(\"Step3 : Apply Perspective transform\")\n",
    "cv2.imshow(\"Warped\", warped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# Step3. Apply Adaptive Threshold\n",
    "# ì´ë¯¸ì§€ ìŠ¤ìº”íš¨ê³¼ì£¼ê¸°\n",
    "warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "warped = cv2.adaptiveThreshold(warped, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "\n",
    "print(\"Step4 : Apply Adaptive Threshold\")\n",
    "cv2.imshow(\"Original\", orig)\n",
    "cv2.imshow(\"Scanned\", warped)\n",
    "img2 = cv2.imwrite('samples/scannedImage.png', warped)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "\n",
    "def ocr_tesseract(img):\n",
    "    im = Image.open(img)\n",
    "    text = pytesseract.image_to_string(im, lang='kor+eng')\n",
    "    im.show()\n",
    "    print(text)\n",
    "    \n",
    "ocr_tesseract('samples/scannedImage.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "mser = cv2.MSER_create()\n",
    "regions,_ = mser.detectRegions(gray)\n",
    "clone = img.copy()\n",
    "hulls = [cv2.convexHull(p.reshape(-1, 1, 2)) for p in regions]\n",
    "remove1 = []\n",
    "for i,c1 in enumerate(hulls):\n",
    "    x, y, w, h = cv2.boundingRect(c1)\n",
    "    r1_start = (x, y)\n",
    "    r1_end = (x+w, y+h)\n",
    "    for j,c2 in enumerate(hulls):\n",
    "        if i == j:\n",
    "            continue\n",
    "        x, y, w, h = cv2.boundingRect(c2)\n",
    "        r2_start = (x, y)\n",
    "        r2_end = (x+w, y+h)\n",
    "        if r1_start[0]> r2_start[0] and r1_start[1] > r2_start[1] and r1_end[0] < r2_end[0] and r1_end[1] < r2_end[1]:\n",
    "            remove1.append(i)\n",
    "\n",
    "for j,cnt in enumerate(hulls):\n",
    "    if j in remove1: continue\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    margin = 10\n",
    "    cv2.rectangle(clone, (x-margin, y-margin), (x + w + margin, y + h + margin), (0, 255, 0), 1)\n",
    "\n",
    "cv2.imshow('mser', clone)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "mask = np.zeros((img.shape[0], img.shape[1], 1), dtype=np.uint8)\n",
    "\n",
    "for j,cnt in enumerate(hulls):\n",
    "    if j in remove1: continue\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    margin = 10\n",
    "    cv2.rectangle(mask, (x-margin, y-margin), (x + w + margin, y + h + margin), (255, 255, 255), -1)\n",
    "\n",
    "text_only = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "cv2.imshow(\"text only\", text_only)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP1 : Edge Detection\n",
      "STEP2 : Find Contours of Paper\n",
      "Step3 : Apply Perspective transform\n",
      "Step4 : Apply Adaptive Threshold\n",
      "-----ëª…í•¨ì£¼ì¸ ì •ë³´-----\n",
      "{'company': '(ì£¼)ì•„ì´íˆ¬ë§¥ìŠ¤', 'email': 'sjchoi@i2max.co.kr', 'role': 'ì‚¬ì›', 'region': 'ì„œìš¸ì‹œ ë§ˆí¬êµ¬ ë§ˆí¬ëŒ€ë¡œ Ã—ë¹Œë”© 7ì¸µ (04143)', 'Mobile': '01071581385', 'Tel': '', 'Fax': '023652093'}\n"
     ]
    }
   ],
   "source": [
    "# Step1. Edge Detection\n",
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "# ì´ë¯¸ì§€ ë¡œë“œ í›„ ë†’ì´ ë¹„ìœ¨ ë§žì¶”ê¸°\n",
    "image_path = 'bizcardsample/Crystal.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "orig = image.copy()\n",
    "r = 800.0 / image.shape[0]\n",
    "dim = (int(image.shape[1] * r), 800)\n",
    "image = cv2.resize(image, dim, interpolation= cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "# Gray Scale ë¡œ ë³€í™˜í›„ ì—£ì§€ ì°¾ê¸°\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "edged = cv2.Canny(gray, 20, 200)\n",
    "\n",
    "# ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë³´ì—¬ì£¼ê³ , Edge ë””í…ì…˜\n",
    "print (\"STEP1 : Edge Detection\")\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "# ---------------------------------\n",
    "# Step2. Find Contours of Paper\n",
    "# Edge ìœ¤ê³½ ì°¾ê¸°\n",
    "\n",
    "(cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE) # findContoursë¥¼ í†µí•´ contoursë“¤ì„ ë°˜í™˜ë°›ìŒ\n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse=True)\n",
    "\n",
    "# contour ì°¾ê¸° ë°˜ë³µ(4ê°œì˜ í¬ì¸íŠ¸)\n",
    "for c in cnts:\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "    \n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break\n",
    "\n",
    "# outlne í”„ë¦°íŒ…\n",
    "print(\"STEP2 : Find Contours of Paper\")\n",
    "cv2.drawContours(image, cnts,  -1, (0, 255, 0), 1)\n",
    "cv2.imshow(\"Outline\", image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# Step3. Apply Perspective Transform\n",
    "# ì´ë¯¸ì§€ ë˜‘ë°”ë¡œ ì„¸ìš°ê¸°\n",
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\") # 4ê°œ ê¼­ì§€ì  ì¢Œí‘œ ìž…ë ¥í•  4x2 í–‰ë ¬ ìƒì„±\n",
    "\n",
    "    s = pts.sum(axis = 1)       # (x, y) ì¢Œí‘œì—ì„œ x+y ê³„ì‚° (axis 0=ì—´, 1=í–‰)\n",
    "    rect[0] = pts[np.argmin(s)] # x+yì˜ ìµœëŒ€ê°’ (topLeft)\n",
    "    rect[2] = pts[np.argmax(s)] # x+yì˜ ìµœì†Œê°’ (bottomRight)\n",
    "\n",
    "    diff = np.diff(pts, axis = 1)  # (x, y) ì¢Œí‘œì—ì„œ y-x ê³„ì‚° (axis 0=ì—´, 1=í–‰)\n",
    "    rect[1] = pts[np.argmin(diff)] # y-xì˜ ìµœì†Œê°’ (topRight)\n",
    "    rect[3] = pts[np.argmax(diff)] # y-xì˜ ìµœëŒ€ê°’ (bottomLeft)\n",
    "    return rect\n",
    "\n",
    "rect = order_points(screenCnt.reshape(4, 2) / r)\n",
    "(topLeft, topRight, bottomRight, bottomLeft) = rect\n",
    "\n",
    "w1 = abs(bottomRight[0] - bottomLeft[0])    # í•˜ë‹¨ í­\n",
    "w2 = abs(topRight[0] - topLeft[0])          # ìƒë‹¨ í­\n",
    "h1 = abs(topRight[1] - bottomRight[1])      # ìš°ì¸¡ ë†’ì´\n",
    "h2 = abs(topLeft[1] - bottomLeft[1])        # ì¢Œì¸¡ ë†’ì´\n",
    "\n",
    "maxWidth = int(max([w1, w2]))\n",
    "maxHeight = int(max([h1, h2]))\n",
    "\n",
    "dst = np.float32([[0, 0], [maxWidth, 0], [maxWidth, maxHeight], [0, maxHeight]]) # ë³€í™˜ë  í¬ê¸°ë§Œí¼ í–‰ë ¬ ìƒì„±\n",
    "M = cv2.getPerspectiveTransform(rect, dst) # getPerspectiveTransform()í•¨ìˆ˜ë¥¼ í†µí•´ì„œ ë‚˜ë¨¸ì§€ í”½ì…€ì„ ì˜®ê¸°ëŠ” ë§¤íŠ¸ë¦­ìŠ¤ Mì— ë°˜í™˜\n",
    "warped = cv2.warpPerspective(orig, M, (maxWidth, maxHeight)) # Mì„ warpPerspective()ì— ë„£ìŒìœ¼ë¡œì¨ ìµœì¢…ì ìœ¼ë¡œ ë°˜ë“¯í•œ ì‚¬ê°í˜•ìœ¼ë¡œ ë³€í™˜ëœ ì´ë¯¸ì§€ë¥¼ ë°›ìŒ\n",
    "\n",
    "#///////////\n",
    "\n",
    "\n",
    "#ì›ë³¸ê³¼ ìŠ¤ìº”ì´ë¯¸ì§€ ë³´ê¸°\n",
    "print(\"Step3 : Apply Perspective transform\")\n",
    "cv2.imshow(\"Warped\", warped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# Step3. Apply Adaptive Threshold\n",
    "# ì´ë¯¸ì§€ ìŠ¤ìº”íš¨ê³¼ì£¼ê¸°\n",
    "warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "warped = cv2.adaptiveThreshold(warped, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "\n",
    "print(\"Step4 : Apply Adaptive Threshold\")\n",
    "cv2.imshow(\"Original\", orig)\n",
    "cv2.imshow(\"Scanned\", warped)\n",
    "img2 = cv2.imwrite('samples/scannedImage.png', warped)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "def ocr_tesseract(img):\n",
    "    im = Image.open(img)\n",
    "    text = pytesseract.image_to_string(im, lang='kor+eng')\n",
    "    # im.show()\n",
    "    if len(text) < 1 :\n",
    "        \n",
    "        print(\"í•˜ì–€ìƒ‰ì´ ì•„ë‹Œ ë°°ê²½ì—ì„œ ì°ì–´ì£¼ì„¸ìš” ðŸ˜Š\")\n",
    "    else:\n",
    "        text = re.sub('[=,#/\\?:^*\\\"â€»~ã†!ã€â€˜|\\[\\]`\\'â€¦ã€‹\\â€\\â€œ\\â€™Â·]', ' ', text)\n",
    "        text = list(filter(None, text.replace('\\n',' ').split(' ')))\n",
    "        \n",
    "        # --------------------------------------\n",
    "        print(\"-----ëª…í•¨ì£¼ì¸ ì •ë³´-----\")\n",
    "        biz_info ={\"company\": \"\", \"email\": \"\", \"role\": \"\", \"region\": \"\", \"Mobile\": \"\", \"Tel\":\"\", \"Fax\": \"\"}\n",
    "        \n",
    "        \n",
    "        # Company\n",
    "        comp_name = [s for s in text if \"(ì£¼)\" in s]\n",
    "        if comp_name:\n",
    "            biz_info['company'] = comp_name[0]\n",
    "        else:\n",
    "            biz_info['company'] = None\n",
    "        \n",
    "        #Email\n",
    "        email_name = [s for s in text if \"@\" in s]\n",
    "        if email_name:\n",
    "            biz_info['email'] = email_name[0]\n",
    "        else:\n",
    "            biz_info['email'] = None\n",
    "        \n",
    "        #ì§ê¸‰\n",
    "        role_name = [s for s in text if \"ì›\" in s]\n",
    "        if role_name:\n",
    "            biz_info['role'] = role_name[0]\n",
    "        else:\n",
    "            biz_info['role'] = None\n",
    "        \n",
    "        #ì§€ì—­\n",
    "        region_flag = (\"ì‹œ\",\"êµ°\",\"êµ¬\",\"ë¡œ\",\"ë¹Œë”©\", \",\",\"ì¸µ\",\"í˜¸\",\")\")\n",
    "        regions = [\" \".join([name for name in text if name.endswith(region_flag)])]\n",
    "        if role_name:\n",
    "            biz_info['region'] = regions[0]\n",
    "        else:\n",
    "            biz_info['region'] = None\n",
    "        \n",
    "        #Contacts\n",
    "        if \"Mobile\" in text:\n",
    "            mob_idx = text.index(\"Mobile\")\n",
    "            mob = ''.join(text[mob_idx+1:mob_idx+5])\n",
    "            mob = [re.sub(r'[^0-9]', '', mob)][0]\n",
    "            biz_info['Mobile'] = mob\n",
    "        if \"Tel\" in text:    \n",
    "            tel_idx = text.index(\"Tel\")\n",
    "            tel = ''.join(text[tel_idx+1:tel_idx+5])\n",
    "            tel = [re.sub(r'[^0-9]', '', tel)][0]\n",
    "            biz_info['Tel'] = tel\n",
    "        if \"Fax\" in text:     \n",
    "            fax_idx = text.index(\"Fax\")\n",
    "            fax = ''.join(text[fax_idx+1:fax_idx+5])\n",
    "            fax = [re.sub(r'[^0-9]', '', fax)][0]\n",
    "            biz_info['Fax'] = fax   \n",
    "        \n",
    "        print(biz_info)\n",
    "        # print(text)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "ocr_tesseract('samples/scannedImage.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.5\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ocr_tesseract() missing 1 required positional argument: 'img'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2p/mfwxnc5s0x1dkdkjmn_yt5880000gn/T/ipykernel_20628/1972297575.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mocr_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: ocr_tesseract() missing 1 required positional argument: 'img'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "def ocr_tesseract(img):\n",
    "    im = Image.open(img)\n",
    "    text = pytesseract.image_to_string(im, lang='kor+eng')\n",
    "    im.show()\n",
    "    print(text)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ocr_tesseract()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc836340034460e9c5583b996b053fe1fe7ffeb52054821d3ff9d502e04de020"
  },
  "kernelspec": {
   "display_name": "woodeemkn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
